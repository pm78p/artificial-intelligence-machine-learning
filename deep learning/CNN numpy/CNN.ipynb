{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwNpC5conPMS"
   },
   "source": [
    "# NumPy Based CNN block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nud1FqU0nPMX"
   },
   "source": [
    "##   Outline of the Assignment\n",
    "\n",
    "we will be implementing the building blocks of a convolutional neural network\n",
    "\n",
    "1. **`zero padding`**\n",
    "\n",
    "2. **`convolution : Forward`**\n",
    "\n",
    "3. **`convolution : Backwrd`**\n",
    "\n",
    "4. **`Max pooling`**\n",
    "\n",
    "5. **`Batch Normalization in CNN `**\n",
    "\n",
    "\n",
    "\n",
    "**Note** that for every forward function, there is its corresponding backward equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZdngsWVf-1-d",
    "outputId": "4928b761-a1d8-40cc-81ea-5a12017d1ec7"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mlGba2SdnPMZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVLBNfwjnPMh"
   },
   "source": [
    "## 1. Zero Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIofak2KnPMk"
   },
   "source": [
    "Zero-padding adds zeros around the border of an image:\n",
    "\n",
    "**Exercise**  : Implement the following function, which pads all the images of a batch of examples X with zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Xac07WonPMn"
   },
   "source": [
    "shape of X and its zero pad array is :\n",
    "\n",
    "\n",
    "$$ X : (N, C, i_h, i_w)   $$\n",
    "$$  \\text{zeropad}(X) : (N, C, i_h + 2*ph, i_w + 2*pw)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-2rbQl4enPMr"
   },
   "outputs": [],
   "source": [
    "def zero_padding(X, padding):\n",
    "    zero_pad = np.zeros((X.shape[0], X.shape[1] , 2*padding[0]+X.shape[2], 2*padding[1]+X.shape[3]))\n",
    "    zero_pad[:,:,padding[0]: padding[0]+X.shape[2], padding[1]: padding[1]+X.shape[3]] = X    \n",
    "    return zero_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bOvCLShTnPMy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implementation is correct\n",
      "shape of x is : (2, 3, 4, 4)\n",
      "shape of x_pad is : (2, 3, 10, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ab53474a20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test zero_padding function\n",
    "np.random.seed(1968)\n",
    "\n",
    "x = np.random.rand(2, 3 ,4, 4)\n",
    "padding = (3, 2)\n",
    "x_pad = zero_padding(x, padding)\n",
    "\n",
    "\n",
    "assert x_pad.shape==(x.shape[0], x.shape[1], x.shape[2] + 2*padding[0], x.shape[3] + 2*padding[1])\n",
    "assert np.all(x_pad[:, :, padding[0]:padding[0]+x.shape[2], padding[1]:padding[1]+x.shape[3]]==x)\n",
    "\n",
    "print(\"implementation is correct\")\n",
    "print(\"shape of x is :\", x.shape)\n",
    "print(\"shape of x_pad is :\", x_pad.shape)\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0, 0, :, :])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaLgNcJonPM5"
   },
   "source": [
    "## 2.convolution : Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSHkDYrfnPM7"
   },
   "source": [
    "In this Exercise, we implement convolutional neural networks using the NumPy library only.\n",
    "\n",
    "The input X,W are the input of the convolutional layer and the shape of X,W are $(N, C, i_h, i_w)$ , $(F, C, f_h, f_w)$ respectively and The return  value O is the output of the convolutional layer and the shape is $(N, F, O_h, O_w)$ where :\n",
    "\n",
    "$$\\text{stride} : (s_h,s_w)$$\n",
    "\n",
    "$$\\text{padding} : (p_h,p_w)$$\n",
    "\n",
    "$$O_w =\\lfloor \\frac{i_w - f_w + 2*p_w}{s_w} \\rfloor + 1$$\n",
    "\n",
    "$$O_h = \\lfloor\\frac{i_h - f_h + 2*p_h}{s_h}\\rfloor + 1$$\n",
    "$$O(b,f, i ,j)=\\sum_{r=0}^{C-1}\\sum_{k=0}^{f_h-1}\\sum_{l=0}^{f_w-1} W(f,r,k,l) X(b,r,s_h *i +k, s_w  *j +l)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rc6Tt8EGnPM9"
   },
   "outputs": [],
   "source": [
    "def convolution2D(X, W, stride, padding):\n",
    "    \"\"\"\n",
    "    A implementation of the forward pass for a convolutional layer.\n",
    "    \n",
    "    The input consists of N data points, each with C channels, height IH and\n",
    "    width IW .We convolve each input with F different filters, where each filter\n",
    "    spans all C channels and has height FH and width FW.\n",
    "    \n",
    "    \n",
    "    inputs:\n",
    "     - X : input data of shape (N, C, IH, IW)\n",
    "     - W : Filter weight of shape (F, C, FH, FW)\n",
    "     - stride : a tuple of 2 integer (sh, sw)\n",
    "     - padding :a tuple of 2 integer (ph, pw)\n",
    "     \n",
    "    return:\n",
    "     - out : Output data, of shape (N, F, OH, OW) where OH and OW given by\n",
    "     \n",
    "     OH= 1 + int ( (IH + 2*ph - FH)/ sh )\n",
    "     OW= 1 + int ( (IW + 2*pw - FW)/ sw )\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    N, C, IH, IW = X.shape\n",
    "    F, C, FH, FW = W.shape\n",
    "    sh, sw = stride\n",
    "    ph, pw = padding\n",
    "    OH = 1 + int ( (IH + 2*ph - FH)/ sh )\n",
    "    OW = 1 + int ( (IW + 2*pw - FW)/ sw )\n",
    "    #out = np.zeros((OH, OW, N, F))\n",
    "    out = np.zeros((N, F, OH, OW))\n",
    "    X_pad = zero_padding(X, padding)\n",
    "\n",
    "    print(stride)\n",
    "    print(padding)\n",
    "    print(X.shape)\n",
    "    print(X_pad.shape)\n",
    "    print((N, F, OH, OW))\n",
    "    \n",
    "    for b in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(OH):\n",
    "                for j in range(OW):\n",
    "                    for c in range(C):\n",
    "                        for k in range(FH):\n",
    "                            for l in range(FW):\n",
    "                                out[b,f,i,j] += W[ f, c, k, l] * X_pad[ b, c, sh * i + k, sw * j + l]\n",
    "\n",
    "    \n",
    "    out = out.reshape(N, F, OH, OW)\n",
    "    return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuqhD5E8nPNJ"
   },
   "source": [
    "To test implementation, we will compare the results  with tensorflow function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_Ran5YbunPNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "(2, 3)\n",
      "(2, 3, 23, 20)\n",
      "(2, 3, 27, 26)\n",
      "(2, 7, 8, 4)\n",
      "Error : 3.865418435582958e-29\n",
      "output shape : (2, 7, 8, 4)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1973)\n",
    "param1 = {'X':np.random.rand(2, 3, 23, 20), 'W':np.random.rand(7, 3, 6, 6), 'stride':(3, 6), 'padding':(2, 3)}\n",
    "x_tf = np.pad(param1['X'], ((0, 0), (0, 0), (2, 2), (3, 3)), 'constant', constant_values=0)\n",
    "\n",
    "\n",
    "conv_numpy = convolution2D(**param1)\n",
    "conv = tf.nn.conv2d(tf.transpose(x_tf, [0 ,2, 3, 1]), tf.transpose(param1['W'], (2, 3, 1, 0)), [1, 3, 6, 1], 'VALID')\n",
    "conv = tf.transpose(conv, (0, 3, 1, 2))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    conv = sess.run(conv)\n",
    "\n",
    "\n",
    "assert conv.shape==conv_numpy.shape\n",
    "print(\"Error :\", (np.sum(conv - conv_numpy)**2))\n",
    "print(\"output shape :\", conv_numpy.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yam8Y2x8nPNe"
   },
   "source": [
    "** Expected Output: **\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **out shape**\n",
    "        </td>\n",
    "        <td>\n",
    "            (2, 7, 8, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **ERROR**\n",
    "        </td>\n",
    "        <td>\n",
    "            2.5559093329160782e-28\n",
    "       </td>\n",
    "    </tr>\n",
    "    \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRFXIZfwnPNg"
   },
   "source": [
    "## 3.convolution : Backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEf-K0MKnPNi"
   },
   "source": [
    "### 3.1 - Backward  w.r.t. filter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1guVkIsfnPNk"
   },
   "source": [
    "This is the formula for computing a $\\frac{\\partial L}{\\partial W}$ for a single $W(f^\\prime,c^\\prime,k^\\prime ,l^\\prime )$ that $W$ is 4-D array as a filter in convolution operation with shape $(F,C,f_h,f_w)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmJRQzNRnPNm"
   },
   "source": [
    "$$\\frac{\\partial L}{\\partial W(f^\\prime,c^\\prime,k^\\prime ,l^\\prime )} = \\sum_{b=0}^{N-1}\\left (\\sum_{i=0}^{O_h-1}\\sum_{j=0}^{O_w-1} \\frac{\\partial L}{\\partial O(b,f^\\prime,i,j)} \\frac{\\partial O(i,j)}{\\partial W(f^\\prime,c^\\prime,k^\\prime ,l^\\prime )}\\right ) = \\sum_{b=0}^{N-1}\\left (\\sum_{i=0}^{O_w-1}\\sum_{j=0}^{O_h-1} \\frac{\\partial L}{\\partial O(b,f^\\prime,i,j)}  X(b,c^\\prime, s_h*i +k^\\prime, s_w*j +l^\\prime) \\right )$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g2g-PgNmnPNo"
   },
   "outputs": [],
   "source": [
    "def convolution2D_backward_filter(out_grad, X, W, stride):\n",
    "    \"\"\"\n",
    "    A implementation of the backward pass for a convolutional layer.\n",
    "    \n",
    "    inputs:\n",
    "     - out_grad  : gradient of the Loss with respect to the output of the conv layer with shape (N, F, OW, OH)\n",
    "     - X : input data of shape (N, C, IH, IW)\n",
    "     - W : Filter weight of shape (F, C, FH, FW)\n",
    "     - stride : a list of [sh, sw]\n",
    "     \n",
    "    return:\n",
    "     - dW : Gradient with respect to W\n",
    "    \n",
    "    \"\"\"\n",
    "    N, C, IH, IW = X.shape\n",
    "    F, C, FH, FW = W.shape\n",
    "    sh, sw = stride\n",
    "    _ ,_ , OH, OW = out_grad.shape\n",
    "\n",
    "    dW = np.zeros((F,C,OH,OW))\n",
    "    \n",
    "    for f in range(F):\n",
    "        for c in range(C):\n",
    "            for k in range(OW):\n",
    "                for l in range(OH):\n",
    "                    for b in range(N):\n",
    "                        for i in range(OW):\n",
    "                            for j in range(OH):\n",
    "                                dW[f, c, k, l] += out_grad[b, f, i, j] * X[b, c, sh * i + k, sw * j + l]\n",
    "\n",
    "    \n",
    "    return dW\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "N5GrLdnlnPNu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error  : 7.636173562539394e-28\n",
      "dW_tf  : 5340.576411697173\n",
      "dW  : 5340.576411697173\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1345)\n",
    "\n",
    "param = {'X':np.random.rand(2, 3, 10,10), 'W':np.random.rand(7, 3, 4, 4), 'stride':(2, 2)}\n",
    "c_1 = np.ones((2, 7, 4, 4))   \n",
    "dw = convolution2D_backward_filter(c_1, **param)\n",
    "\n",
    "\n",
    "\n",
    "w = tf.Variable(tf.transpose(param['W'],(2, 3, 1, 0)),name='v')\n",
    "c = tf.nn.conv2d(tf.transpose(param['X'],[0, 2, 3, 1]), w, [1, 2, 2, 1], 'VALID')\n",
    "loss = tf.reduce_sum(c)\n",
    "dw_tf = tf.gradients(loss, w)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dw_tf = sess.run(dw_tf)\n",
    "\n",
    "\n",
    "\n",
    "dw = np.transpose(dw, (2, 3 ,1, 0))\n",
    "print(\"Error  :\", np.sum((dw-dw_tf[0])**2))\n",
    "print(\"dW_tf  :\", np.sum(dw_tf[0]))\n",
    "print(\"dW  :\", np.sum(dw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzXtSW_InPN0"
   },
   "source": [
    "** Expected Output: **\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **dW_tf**\n",
    "        </td>\n",
    "        <td>\n",
    "            5340.576411697173\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **dW**\n",
    "        </td>\n",
    "        <td>\n",
    "            5340.576411697173\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Error**\n",
    "        </td>\n",
    "        <td>\n",
    "            2.473867798773093e-27\n",
    " </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxyz9o2GnPN3"
   },
   "source": [
    "### 3.2 - Backward  w.r.t. input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7P5oyWXnPN5"
   },
   "source": [
    "This is the formula for computing a $\\frac{\\partial L}{\\partial X}$ for a single $X(b^\\prime,c^\\prime,k^\\prime ,l^\\prime )$ that $X$ is 4-D array as a input in convolution operation with shape $(N,C,i_h,i_w)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLGji2fKnPN7"
   },
   "source": [
    "$$\\frac{\\partial L}{\\partial X(b^\\prime,c^\\prime,k^\\prime ,l^\\prime )} = \\sum_{f=0}^{F-1}\\left (\\sum_{i=0}^{O_h-1}\\sum_{j=0}^{O_w-1} \\frac{\\partial L}{\\partial O(b^\\prime,f,i,j)} \\frac{\\partial O(b^\\prime,f,i,j)}{\\partial X(b^\\prime,c^\\prime,k^\\prime ,l^\\prime )}\\right ) = \\sum_{f=0}^{F-1}\\left (\\sum_{i=0}^{O_h-1}\\sum_{j=0}^{O_w-1} \\frac{\\partial L}{\\partial O(b^\\prime,f,i,j)} W(f,c^\\prime,k^\\prime - s_h*i, l^\\prime - s_w*j) \\right )$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k9-Ez6OQnPN-"
   },
   "outputs": [],
   "source": [
    "def convolution2D_backward_input(out_grad, X, W, stride):\n",
    "    \"\"\"\n",
    "    A implementation of the backward pass for a convolutional layer.\n",
    "    \n",
    "    inputs:\n",
    "     - out_grad  : gradient of the Loss with respect to the output of the conv layer with shape (N, F, OW, OH)\n",
    "     - X : input data of shape (N, C, IH, IW)\n",
    "     - W : Filter weight of shape (F, C, FH, FW)\n",
    "     - stride : a list of [sh, sw]\n",
    "     \n",
    "    return:\n",
    "     - dX : Gradient with respect to X\n",
    "    \n",
    "    \"\"\"\n",
    "    N, C, IH, IW = X.shape\n",
    "    F, C, FH, FW = W.shape\n",
    "    sh, sw = stride\n",
    "    _ , _, OH, OW = out_grad.shape\n",
    "\n",
    "    dX = np.zeros(X.shape)\n",
    "\n",
    "    for f in range(F):\n",
    "        for c in range(C):\n",
    "            for k in range(IH):\n",
    "                for l in range(IW):\n",
    "                    for b in range(N):\n",
    "                        for i in range(OH):\n",
    "                            for j in range(OW):\n",
    "                                t1 = k - sh * i\n",
    "                                t2 = l - sw * j\n",
    "                                if t1 >= 0 and t2 >= 0 and t1 < FH and t2 < FW:\n",
    "                                    dX[b, c, k, l] += out_grad[b, f, i, j] * W[f, c, t1, t2]\n",
    "\n",
    "    \n",
    "    return dX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VJwwMZqInPOE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is : 0.0\n",
      "dX_tf is : 208.39287018595633\n",
      "dX is : 208.39287018595633\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1992)\n",
    "\n",
    "param = {'X':np.random.rand(5, 3, 6, 6), 'W':np.random.rand(2, 3, 2, 2), 'stride':(3,3)}\n",
    "grad = np.ones((5, 2, 2, 2))\n",
    "dx = convolution2D_backward_input(grad, **param)\n",
    "\n",
    "\n",
    "\n",
    "w = tf.Variable(tf.transpose(param['W'], (2, 3, 1, 0)), name='v')\n",
    "x = tf.Variable(tf.transpose(param['X'], [0, 2, 3, 1]), name='x')\n",
    "c = tf.nn.conv2d(x, w, [1,3,3,1], 'VALID')\n",
    "loss = tf.reduce_sum(c)\n",
    "g = tf.gradients(loss, x)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dx_tf = sess.run(g)\n",
    "dx = np.transpose(dx, (0, 2, 3, 1))\n",
    "\n",
    "\n",
    "assert dx.shape==dx_tf[0].shape\n",
    "print(\"Error is :\", np.sum((dx-dx_tf[0])**2))\n",
    "print(\"dX_tf is :\", np.sum(dx_tf[0]))\n",
    "print(\"dX is :\", np.sum(dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmIIdIwqnPOL"
   },
   "source": [
    "** Expected Output: **\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **dX_tf**\n",
    "        </td>\n",
    "        <td>\n",
    "            208.39287018595633\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **dX**\n",
    "        </td>\n",
    "        <td>\n",
    "            208.39287018595633\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Error**\n",
    "        </td>\n",
    "        <td>\n",
    "            0.0\n",
    " </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01DiIHblnPOO"
   },
   "source": [
    "## 4.Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0s_-ssYznPOQ"
   },
   "source": [
    "### 4.1 - forward max pooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zuq2YNg1nPOS"
   },
   "source": [
    "The pooling layer reduces the height and width of the input. It helps reduce computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_SFsAmLnPOV"
   },
   "source": [
    " - Max-pooling layer: slides an ($f, f$) window with stride $s$ over the input and stores the max value of the window in the output.\n",
    "\n",
    "in function below X is input and shape of X is $(N, C, i_h, i_w)$  and output is shape $(N, C, O_h, O_w)$ that :\n",
    "\n",
    " $$O_h =\\lfloor\\frac{i_h - f }{s}\\rfloor + 1$$\n",
    " $$O_w =\\lfloor\\frac{i_w - f }{s}\\rfloor + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VaWcSaPKnPOZ"
   },
   "outputs": [],
   "source": [
    "def pool_forward(X, f, s):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    input:\n",
    "       - X : numpy array of shape (N, C, IH, IW)\n",
    "       - f : int, filter size in height and width dim\n",
    "       - s : int\n",
    "    \n",
    "    Returns:\n",
    "       - pool : output of the pool layer, a numpy array of shape (N, C, OH, OW) where OH and OW given by\n",
    "       \n",
    "       OH = 1 + int((IH - f)/s)\n",
    "       OW = 1 + int((IW - f)/s)\n",
    "    \n",
    "    \"\"\"\n",
    "    N, C, IH, IW = X.shape\n",
    "    OH = 1 + int((IH - f)/s)\n",
    "    OW = 1 + int((IW - f)/s)\n",
    "    pool = np.zeros((N, C, OH, OW))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for i in range(OH):\n",
    "                for j in range(OW):\n",
    "                    tmp = X[n, c, i*s : i*s + f, j*s : j*s + f]\n",
    "                    pool[n, c, i, j] = np.amax(tmp)\n",
    "        \n",
    "    return pool\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JtN8FqAlnPOj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implementation is correct\n",
      "output shape : (2, 3, 2, 2)\n",
      "output : [[[[0.46800661 0.6818562 ]\n",
      "   [0.95191188 0.58676102]]\n",
      "\n",
      "  [[0.6288546  0.99632119]\n",
      "   [0.80094484 0.96251272]]\n",
      "\n",
      "  [[0.67012954 0.80356619]\n",
      "   [0.91517917 0.83174796]]]\n",
      "\n",
      "\n",
      " [[[0.80458243 0.97712759]\n",
      "   [0.91272943 0.86171778]]\n",
      "\n",
      "  [[0.8827965  0.95316097]\n",
      "   [0.95877647 0.98136021]]\n",
      "\n",
      "  [[0.96840121 0.87088313]\n",
      "   [0.70449495 0.89625081]]]]\n",
      "Error : 0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1975)\n",
    "x=np.random.rand(2,3,23,23)\n",
    "\n",
    "hyper_param={\"f\":2, \"s\" :11}\n",
    "c=pool_forward(x,**hyper_param)\n",
    "\n",
    "pool_tf = tf.nn.max_pool(tf.transpose(x,(0,2,3,1)),[1,2,2,1],[1,11,11,1],'VALID') ## tensorflow api\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    pool_tf =sess.run(pool_tf)\n",
    "    \n",
    "pool_tf=np.transpose(pool_tf, (0,3,1,2))\n",
    "\n",
    "assert c.shape==pool_tf.shape\n",
    "assert (c==pool_tf).all()\n",
    "\n",
    "print(\"implementation is correct\")\n",
    "print(\"output shape :\", c.shape)\n",
    "print(\"output :\", c)\n",
    "print(\"Error :\" ,np.sum((c-pool_tf)**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr0tWI2qnPOp"
   },
   "source": [
    "** Expected Output: **\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Error**\n",
    "        </td>\n",
    "        <td>\n",
    "            0.0\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "            (2, 3, 2, 2)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "\n",
    "</table>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
